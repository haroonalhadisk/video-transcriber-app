{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Video Transcriber - Kaggle Notebook\n",
        "\n",
        "This notebook allows you to run the Video Transcriber application with a web interface in Kaggle.\n",
        "\n",
        "## Features\n",
        "- Transcribe videos using OpenAI's Whisper speech recognition model\n",
        "- Process batches of videos\n",
        "- Download videos from Instagram\n",
        "- Process transcripts with Groq AI\n",
        "- Save transcriptions to Notion\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "Install the required packages and confirm FFmpeg is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for FFmpeg (should be pre-installed on Kaggle)\n",
        "!ffmpeg -version\n",
        "\n",
        "# Install Python packages\n",
        "!pip install torch openai-whisper requests gradio instaloader browser_cookie3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Application Files\n",
        "\n",
        "Let's create all the necessary files for the application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create working directory\n",
        "!mkdir -p /kaggle/working/video-transcriber\n",
        "%cd /kaggle/working/video-transcriber"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Upload Application Files\n",
        "\n",
        "You need to upload the application files to this notebook. Required files:\n",
        "\n",
        "- main.py\n",
        "- web_ui.py\n",
        "- notion_integration.py\n",
        "- groq_integration.py\n",
        "- instaloader_integration.py\n",
        "\n",
        "You can either:\n",
        "1. Upload files using the \"Add Data\" button in Kaggle\n",
        "2. Copy and paste code into cells and save them as files (shown below)\n",
        "3. Clone from a GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Clone from GitHub if available\n",
        "# !git clone https://github.com/haroonalhadisk/video-transcriber-app.git .\n",
        "\n",
        "# Option 2: Create placeholder for upload\n",
        "print(\"Please upload the application files using Kaggle's 'Add Data' feature.\")\n",
        "print(\"Or create the files directly in cells below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Application Settings Directory\n",
        "\n",
        "Create a directory for settings to persist within the Kaggle session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the settings directory\n",
        "!mkdir -p ~/.videotranscriber"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Run the Web Interface\n",
        "\n",
        "Launch the application in web mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python main.py --web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Tips\n",
        "\n",
        "### Working with Kaggle Datasets\n",
        "\n",
        "You can access files from Kaggle datasets directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List files in the input directory (if you've added a dataset)\n",
        "!ls -la /kaggle/input/\n",
        "\n",
        "# Example of accessing a specific dataset\n",
        "# !ls -la /kaggle/input/your-dataset-name/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Results to Output Directory\n",
        "\n",
        "Kaggle automatically preserves files in the `/kaggle/working` directory as outputs from your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dedicated output directory\n",
        "!mkdir -p /kaggle/working/transcriptions\n",
        "print(\"Use this directory in the web interface for outputs: /kaggle/working/transcriptions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance Tips\n",
        "\n",
        "Kaggle provides GPU acceleration which can speed up Whisper transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "\n",
        "1. Check that all application files are correctly uploaded or created\n",
        "2. Verify paths in the web interface match Kaggle's directory structure\n",
        "3. For Instagram issues, try username/password login instead of browser cookies\n",
        "4. Be mindful of Kaggle's session time limits for long transcription jobs\n",
        "5. Use smaller models or batch sizes for large workloads"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30599,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
